URLS=[
"pycollector/index.html",
"pycollector/dataset.html",
"pycollector/detection.html",
"pycollector/video.html",
"pycollector/user.html",
"pycollector/label.html",
"pycollector/util.html",
"pycollector/recognition.html",
"pycollector/version.html",
"pycollector/backend.html",
"pycollector/globals.html",
"pycollector/project.html"
];
INDEX=[
{
"ref":"pycollector",
"url":0,
"doc":""
},
{
"ref":"pycollector.dataset",
"url":1,
"doc":""
},
{
"ref":"pycollector.dataset.disjoint_activities",
"url":1,
"doc":"",
"func":1
},
{
"ref":"pycollector.dataset.asmeva",
"url":1,
"doc":"Convert a list of collector.dataset.Video() to MEVA annotation style",
"func":1
},
{
"ref":"pycollector.dataset.TorchDataset",
"url":1,
"doc":"Moved to vipy.torch.TorchDataset"
},
{
"ref":"pycollector.dataset.TorchTensordir",
"url":1,
"doc":"Moved to vipy.torch.TorchTensordir"
},
{
"ref":"pycollector.dataset.Dataset",
"url":1,
"doc":"Additional methods beyond  vipy.dataset.Dataset that are specific to collector style datasets"
},
{
"ref":"pycollector.dataset.Dataset.collectors",
"url":1,
"doc":"",
"func":1
},
{
"ref":"pycollector.dataset.Dataset.os",
"url":1,
"doc":"",
"func":1
},
{
"ref":"pycollector.dataset.Dataset.device",
"url":1,
"doc":"",
"func":1
},
{
"ref":"pycollector.dataset.Dataset.geolocation",
"url":1,
"doc":"",
"func":1
},
{
"ref":"pycollector.detection",
"url":2,
"doc":""
},
{
"ref":"pycollector.detection.TorchNet",
"url":2,
"doc":""
},
{
"ref":"pycollector.detection.FaceDetector",
"url":2,
"doc":"Faster R-CNN based face detector"
},
{
"ref":"pycollector.detection.Yolov5",
"url":2,
"doc":"Yolov5 based object detector >>> d = heyvi.detection.Detector() >>> d(vipy.image.vehicles( .show()"
},
{
"ref":"pycollector.detection.Yolov3",
"url":2,
"doc":"Yolov3 based object detector >>> d = heyvi.detection.Detector() >>> d(vipy.image.vehicles( .show()"
},
{
"ref":"pycollector.detection.ObjectDetector",
"url":2,
"doc":"Default object detector"
},
{
"ref":"pycollector.detection.MultiscaleObjectDetector",
"url":2,
"doc":"Given a list of images, break each one into a set of overlapping tiles, and ObjectDetector() on each, then recombining detections"
},
{
"ref":"pycollector.detection.VideoDetector",
"url":2,
"doc":"Iterate ObjectDetector() over each frame of video, yielding the detected frame"
},
{
"ref":"pycollector.detection.MultiscaleVideoDetector",
"url":2,
"doc":"Given a list of images, break each one into a set of overlapping tiles, and ObjectDetector() on each, then recombining detections"
},
{
"ref":"pycollector.detection.VideoTracker",
"url":2,
"doc":"Default object detector"
},
{
"ref":"pycollector.detection.FaceTracker",
"url":2,
"doc":"Faster R-CNN based face detector"
},
{
"ref":"pycollector.detection.MultiscaleVideoTracker",
"url":2,
"doc":"MultiscaleVideoTracker() class"
},
{
"ref":"pycollector.detection.Proposal",
"url":2,
"doc":"Default object detector"
},
{
"ref":"pycollector.detection.VideoProposal",
"url":2,
"doc":"heyvi.detection.VideoProposal() class. Track-based object proposals in video."
},
{
"ref":"pycollector.detection.FaceProposalRefinement",
"url":2,
"doc":""
},
{
"ref":"pycollector.detection.TrackProposalRefinement",
"url":2,
"doc":""
},
{
"ref":"pycollector.detection.VideoProposalRefinement",
"url":2,
"doc":"heyvi.detection.VideoProposalRefinement() class. Track-based object proposal refinement of a weakly supervised loose object box from a human annotator."
},
{
"ref":"pycollector.detection.ActorAssociation",
"url":2,
"doc":"heyvi.detection.VideoAssociation() class Select the best object track of the target class associated with the primary actor class by gated spatial IOU and distance. Add the best object track to the scene and associate with all activities performed by the primary actor."
},
{
"ref":"pycollector.video",
"url":3,
"doc":""
},
{
"ref":"pycollector.video.Video",
"url":3,
"doc":"pycollector.video.Video class"
},
{
"ref":"pycollector.video.Video.cast",
"url":3,
"doc":"Cast a conformal vipy object to this class. This is useful for downcast and upcast conversion of video objects.",
"func":1
},
{
"ref":"pycollector.video.Video.from_json",
"url":3,
"doc":"Restore an object serialized with self.json() Usage: >>> vs = vipy.video.Scene.from_json(v.json( ",
"func":1
},
{
"ref":"pycollector.video.Video.json",
"url":3,
"doc":"Return JSON encoded string of this object. This may fail if attributes contain non-json encodeable object",
"func":1
},
{
"ref":"pycollector.video.Video.appjson",
"url":3,
"doc":"Export JSON that is equivalent to the output of the mobile app, with annotations relative to the video file (not the filter chain)",
"func":1
},
{
"ref":"pycollector.video.Video.isedited",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.editedat",
"url":3,
"doc":"Android appends an '_ ' timestamp as milliseconds since epoch (POSIX timestamp), iOS will replace the first '_datetimestr' with a new datetimest",
"func":1
},
{
"ref":"pycollector.video.Video.edited",
"url":3,
"doc":"Return the datetime representation of the editedat() string",
"func":1
},
{
"ref":"pycollector.video.Video.variant",
"url":3,
"doc":"Category variant",
"func":1
},
{
"ref":"pycollector.video.Video.geolocation",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.fetch",
"url":3,
"doc":"Download JSON and MP4 if not already downloaded",
"func":1
},
{
"ref":"pycollector.video.Video.fetchvideo",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.fetchjson",
"url":3,
"doc":"Download JSON if not already downloaded",
"func":1
},
{
"ref":"pycollector.video.Video.is_json_loaded",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.hasjson",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.hasMP4",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.activity_categories",
"url":3,
"doc":"Return a set of unique activity categories in the video, not including object categories",
"func":1
},
{
"ref":"pycollector.video.Video.quicklooks",
"url":3,
"doc":"Return a vipy.image.Image object containing a montage quicklook for each of the activities in this video. Usage: >>> filenames = [im.saveas('/path/to/quicklook.jpg') for im in self.quicklooks()]",
"func":1
},
{
"ref":"pycollector.video.Video.trim",
"url":3,
"doc":"Temporally clip the video so that the video start is the beginning of the first activity, and the end of the video is the end of the last activity. Optionally add a temporal pad of padframes before and after the clip",
"func":1
},
{
"ref":"pycollector.video.Video.timestamp",
"url":3,
"doc":"Return collected_date from json as a datetime object, WARNING: older veresion of the app do not include timezone info in this string, so this datetime is not offset aware This timestamp is in the local timezone of the collector! Do not use this for any datetime arithmetic without assigning a timezone from the geolocation",
"func":1
},
{
"ref":"pycollector.video.Video.uploaded",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.metadata",
"url":3,
"doc":"Return a dictionary of metadata about this video. This is an alias for the 'attributes' dictionary.",
"func":1
},
{
"ref":"pycollector.video.Video.videoid",
"url":3,
"doc":"Return a unique video identifier for this video, as specified in the 'video_id' attribute, or by SHA1 hash of the  vipy.video.Video.filename and  vipy.video.Video.url . Args: newid: [str] If not None, then update the video_id as newid. Returns: The video ID if newid=None else self  note - If the video filename changes (e.g. from transformation), and video_id is not set in self.attributes, then the video ID will change. - If a video does not have a filename or URL or a video ID in the attributes, then this will return None - To preserve a video ID independent of transformations, set self.setattribute('video_id', ${MY_ID}), or pass in newid",
"func":1
},
{
"ref":"pycollector.video.Video.collectorid",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.subjectid",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.collectionid",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.collection_name",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.collection",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.duration",
"url":3,
"doc":"Video length in seconds",
"func":1
},
{
"ref":"pycollector.video.Video.quickshow",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.downcast",
"url":3,
"doc":"Convert from pycollector.video to vipy.video.Scene by downcasting class",
"func":1
},
{
"ref":"pycollector.video.Video.upcast",
"url":3,
"doc":"Convert from pycollector.video to pycollector.admin.video by upcasting class, available to admins only",
"func":1
},
{
"ref":"pycollector.video.Video.project",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.program",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.object_detection",
"url":3,
"doc":"Run an object detector on a given frame of video. It is more efficient to construct an ObjectDetector() object once and reuse it.",
"func":1
},
{
"ref":"pycollector.video.Video.face_detection",
"url":3,
"doc":"Run face detection on a given frame of video. It is more efficient to construct a FaceDetector() object once and reuse it.",
"func":1
},
{
"ref":"pycollector.video.Video.faces",
"url":3,
"doc":"Alias for face_detection",
"func":1
},
{
"ref":"pycollector.video.Video.appversion",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.Video.app_version",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.video.last",
"url":3,
"doc":"",
"func":1
},
{
"ref":"pycollector.user",
"url":4,
"doc":""
},
{
"ref":"pycollector.user.User",
"url":4,
"doc":"User class for collector's user management Args: username ([str]): username of pycollector. password ([str], optional): password for the user. Defaults to None."
},
{
"ref":"pycollector.user.User.refresh",
"url":4,
"doc":"",
"func":1
},
{
"ref":"pycollector.user.User.login",
"url":4,
"doc":"[summary] Args: username ([str]): username of pycollector. password ([str], optional): password for the user. Defaults to None.",
"func":1
},
{
"ref":"pycollector.user.User.get_ssm_param",
"url":4,
"doc":"[summary]",
"func":1
},
{
"ref":"pycollector.user.User.is_token_expired",
"url":4,
"doc":"[summary] Returns: [type]: [description]",
"func":1
},
{
"ref":"pycollector.user.User.token_expired_by",
"url":4,
"doc":"",
"func":1
},
{
"ref":"pycollector.user.User.is_authenticated",
"url":4,
"doc":"",
"func":1
},
{
"ref":"pycollector.user.User.add_user_to_group",
"url":4,
"doc":"Check if the current user is already in the pycollector user group, if not add the user to group Returns: [type]: [description]",
"func":1
},
{
"ref":"pycollector.user.User.username",
"url":4,
"doc":""
},
{
"ref":"pycollector.user.User.cognito_username",
"url":4,
"doc":""
},
{
"ref":"pycollector.user.User.lambda_client",
"url":4,
"doc":""
},
{
"ref":"pycollector.label",
"url":5,
"doc":""
},
{
"ref":"pycollector.label.Label",
"url":5,
"doc":""
},
{
"ref":"pycollector.label.piplabel_to_mevalabel",
"url":5,
"doc":"",
"func":1
},
{
"ref":"pycollector.label.mevalabel_to_index",
"url":5,
"doc":"",
"func":1
},
{
"ref":"pycollector.label.piplabel_to_index",
"url":5,
"doc":"",
"func":1
},
{
"ref":"pycollector.label.pip_250k_powerset",
"url":5,
"doc":"",
"func":1
},
{
"ref":"pycollector.util",
"url":6,
"doc":""
},
{
"ref":"pycollector.util.mergedict",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.lowerif",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.isday",
"url":6,
"doc":"Is the yyyymmdd formatted as 'YYYY-MM-DD' such as '2020-03-18'",
"func":1
},
{
"ref":"pycollector.util.isdate",
"url":6,
"doc":"Alias for isday",
"func":1
},
{
"ref":"pycollector.util.fromdate",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.ismonday",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.is_more_recent_than",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.yyyymmdd_to_date",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.is_email_address",
"url":6,
"doc":"Quick and dirty, will throw an error on blank characters if strict=True",
"func":1
},
{
"ref":"pycollector.util.allmondays",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.timestamp_YYYYMMDD_HHMMSS",
"url":6,
"doc":"Datetime stamp in eastern timezone with second resolution",
"func":1
},
{
"ref":"pycollector.util.istimestamp_YYYYMMDD_HHMMSS",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.fromtimestamp_YYYYMMDD_HHMMSS",
"url":6,
"doc":"Assumed eastern timezone",
"func":1
},
{
"ref":"pycollector.util.timestamp",
"url":6,
"doc":"Datetime stamp in eastern timezone with microsecond resolution",
"func":1
},
{
"ref":"pycollector.util.istimestamp",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.fromtimestamp",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.clockstamp",
"url":6,
"doc":"Datetime stamp in eastern timezone with second resolution",
"func":1
},
{
"ref":"pycollector.util.datestamp",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.today",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.fromclockstamp",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.allmondays_since",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.lastmonday",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.lastweek_monday",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.nextsunday",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.util.nextday",
"url":6,
"doc":"",
"func":1
},
{
"ref":"pycollector.recognition",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.ActivityRecognition",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.PIP_250k",
"url":7,
"doc":"Activity recognition using people in public - 250k stabilized"
},
{
"ref":"pycollector.recognition.PIP_250k.dump_patches",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.PIP_250k.training",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.PIP_250k.forward",
"url":7,
"doc":"Same as :meth: torch.nn.Module.forward() , however in Lightning you want this to define the operations you want to use for prediction (i.e.: on a server or as a feature extractor). Normally you'd call  self() from your :meth: training_step method. This makes it easy to write a complex system for training with the outputs you'd want in a prediction setting. You may also find the :func: ~pytorch_lightning.core.decorators.auto_move_data decorator useful when using the module outside Lightning in a production setting. Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Predicted output Examples:  code-block python  example if we were using this model as a feature extractor def forward(self, x): feature_maps = self.convnet(x) return feature_maps def training_step(self, batch, batch_idx): x, y = batch feature_maps = self(x) logits = self.classifier(feature_maps)   . return loss  splitting it this way allows model to be used a feature extractor model = MyModelAbove() inputs = server.get_request() results = model(inputs) server.write_results(results)        -  This is in stark contrast to torch.nn.Module where normally you would have this: def forward(self, batch): x, y = batch feature_maps = self.convnet(x) logits = self.classifier(feature_maps) return logits",
"func":1
},
{
"ref":"pycollector.recognition.PIP_370k",
"url":7,
"doc":"Activity recognition using people in public - 250k stabilized"
},
{
"ref":"pycollector.recognition.PIP_370k.dump_patches",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.PIP_370k.training",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.PIP_370k.forward",
"url":7,
"doc":"Same as :meth: torch.nn.Module.forward() , however in Lightning you want this to define the operations you want to use for prediction (i.e.: on a server or as a feature extractor). Normally you'd call  self() from your :meth: training_step method. This makes it easy to write a complex system for training with the outputs you'd want in a prediction setting. You may also find the :func: ~pytorch_lightning.core.decorators.auto_move_data decorator useful when using the module outside Lightning in a production setting. Args:  args: Whatever you decide to pass into the forward method.  kwargs: Keyword arguments are also possible. Return: Predicted output Examples:  code-block python  example if we were using this model as a feature extractor def forward(self, x): feature_maps = self.convnet(x) return feature_maps def training_step(self, batch, batch_idx): x, y = batch feature_maps = self(x) logits = self.classifier(feature_maps)   . return loss  splitting it this way allows model to be used a feature extractor model = MyModelAbove() inputs = server.get_request() results = model(inputs) server.write_results(results)        -  This is in stark contrast to torch.nn.Module where normally you would have this: def forward(self, batch): x, y = batch feature_maps = self.convnet(x) logits = self.classifier(feature_maps) return logits",
"func":1
},
{
"ref":"pycollector.recognition.ActivityTracker",
"url":7,
"doc":"Video Activity detection. Args (__call__): vi [generator of  vipy.video.Scene ]: The input video to be updated in place with detections. This is a generator which is output from heyvi.detection.MultiscaleVideoTracker.__call__ activityiou [float]: The minimum temporal iou for activity assignment mirror [bool]: If true, encode using the mean of a video encoding and the mirrored video encoding. This is slower as it requires 2x GPU forward passes minprob [float]: The minimum probability for new activity detection trackconf [float]: The minimum object detection confidence for new tracks maxdets [int]: The maximum number of allowable detections per frame. If there are more detections per frame tha maxdets, sort them by confidence and use only the top maxdets best avgdets [int]: The number of allowable detections per frame if throttled buffered [bool]: If true, then buffer streams. This is useful for activity detection on live streams. finalized [bool, int]: If False then do not finalize(), If True finalize() only at the end, If int, then finalize every int frames. This is useful for streaming activity detection on unbounded inputs. Returns: The input video is updated in place."
},
{
"ref":"pycollector.recognition.ActivityTracker.dump_patches",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.ActivityTracker.training",
"url":7,
"doc":""
},
{
"ref":"pycollector.recognition.ActivityTracker.forward",
"url":7,
"doc":"Overload forward for multi-gpu batch. Don't use torch DataParallel!",
"func":1
},
{
"ref":"pycollector.version",
"url":8,
"doc":""
},
{
"ref":"pycollector.version.num",
"url":8,
"doc":"",
"func":1
},
{
"ref":"pycollector.version.at_least_version",
"url":8,
"doc":"Is versionstring='X.Y.Z' at least the current version?",
"func":1
},
{
"ref":"pycollector.version.is_at_least",
"url":8,
"doc":"Synonym for at_least_version",
"func":1
},
{
"ref":"pycollector.version.is_exactly",
"url":8,
"doc":"",
"func":1
},
{
"ref":"pycollector.backend",
"url":9,
"doc":""
},
{
"ref":"pycollector.backend.API",
"url":9,
"doc":"class for pycollector API Args: object ([type]): [description] Args: username ([type], optional): [description]. Defaults to None. password ([type], optional): [description]. Defaults to None."
},
{
"ref":"pycollector.backend.API.get_project",
"url":9,
"doc":"[summary] Args: -",
"func":1
},
{
"ref":"pycollector.backend.API.videos",
"url":9,
"doc":"[summary] Args: -",
"func":1
},
{
"ref":"pycollector.backend.API.lastvideo",
"url":9,
"doc":"",
"func":1
},
{
"ref":"pycollector.backend.API.new_collection",
"url":9,
"doc":"",
"func":1
},
{
"ref":"pycollector.backend.API.list_collections",
"url":9,
"doc":"",
"func":1
},
{
"ref":"pycollector.backend.API.delete_collection",
"url":9,
"doc":"",
"func":1
},
{
"ref":"pycollector.backend.API.login",
"url":4,
"doc":"[summary] Args: username ([str]): username of pycollector. password ([str], optional): password for the user. Defaults to None.",
"func":1
},
{
"ref":"pycollector.backend.API.get_ssm_param",
"url":4,
"doc":"[summary]",
"func":1
},
{
"ref":"pycollector.backend.API.is_token_expired",
"url":4,
"doc":"[summary] Returns: [type]: [description]",
"func":1
},
{
"ref":"pycollector.backend.API.add_user_to_group",
"url":4,
"doc":"Check if the current user is already in the pycollector user group, if not add the user to group Returns: [type]: [description]",
"func":1
},
{
"ref":"pycollector.globals",
"url":10,
"doc":""
},
{
"ref":"pycollector.globals.cachedir",
"url":10,
"doc":"Set the location to save videos and JSON files when downloaded. This will default to the system temp directory if not set. -This can be set by default by creating the environment variable VIPY_CACHE='/path/to/newdir'",
"func":1
},
{
"ref":"pycollector.globals.logging",
"url":10,
"doc":"Single entry point for enabling/disabling logging vs. printing All vipy functions overload \"from vipy.globals import print\" for simplified readability of code. This global function redirects print or warn to using the standard logging module. If format is provided, this will create a basicConfig handler, but this should be configured by the end-user.",
"func":1
},
{
"ref":"pycollector.globals.warn",
"url":10,
"doc":"",
"func":1
},
{
"ref":"pycollector.globals.print",
"url":10,
"doc":"Main entry point for all print statements in the pycollector package. All pycollector code calls this to print helpful messages. -All print() statements in pycollector are overloaded to call pycollector.globals.print() so that it can be redirected to logging as needed -Printing can be disabled by calling pycollector.globals.silent() -Printing can be redirected to standard python logging by calling pycollector.globals.logging(True)",
"func":1
},
{
"ref":"pycollector.globals.verbose",
"url":10,
"doc":"",
"func":1
},
{
"ref":"pycollector.globals.silent",
"url":10,
"doc":"",
"func":1
},
{
"ref":"pycollector.project",
"url":11,
"doc":""
},
{
"ref":"pycollector.project.Project",
"url":11,
"doc":"collector.project.Project class Projects() are sets of CollectionInstances() and Instances() in a program. Args: username ([str]): username of pycollector. password ([str], optional): password for the user. Defaults to None."
},
{
"ref":"pycollector.project.Project.videos",
"url":11,
"doc":"",
"func":1
},
{
"ref":"pycollector.project.Project.last",
"url":11,
"doc":"",
"func":1
},
{
"ref":"pycollector.project.Project.login",
"url":4,
"doc":"[summary] Args: username ([str]): username of pycollector. password ([str], optional): password for the user. Defaults to None.",
"func":1
},
{
"ref":"pycollector.project.Project.get_ssm_param",
"url":4,
"doc":"[summary]",
"func":1
},
{
"ref":"pycollector.project.Project.is_token_expired",
"url":4,
"doc":"[summary] Returns: [type]: [description]",
"func":1
},
{
"ref":"pycollector.project.Project.add_user_to_group",
"url":4,
"doc":"Check if the current user is already in the pycollector user group, if not add the user to group Returns: [type]: [description]",
"func":1
}
]